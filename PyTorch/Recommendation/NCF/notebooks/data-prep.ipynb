{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/workspace/recommendation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "import pandas as pd\n",
    "from load import implicit_load\n",
    "import torch\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_RATINGS = 20\n",
    "USER_COLUMN = 'user_id'\n",
    "ITEM_COLUMN = 'item_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TestNegSampler:\n",
    "    def __init__(self, train_ratings, nb_neg):\n",
    "        self.nb_neg = nb_neg\n",
    "        self.nb_users = int(train_ratings[:, 0].max()) + 1\n",
    "        self.nb_items = int(train_ratings[:, 1].max()) + 1\n",
    "\n",
    "        # compute unique ids for quickly created hash set and fast lookup\n",
    "        ids = (train_ratings[:, 0] * self.nb_items) + train_ratings[:, 1]\n",
    "        self.set = set(ids)\n",
    "\n",
    "    def generate(self, batch_size=128*1024):\n",
    "        users = torch.arange(0, self.nb_users).reshape([1, -1]).repeat([self.nb_neg, 1]).transpose(0, 1).reshape(-1)\n",
    "\n",
    "        items = [-1] * len(users)\n",
    "\n",
    "        random_items = torch.LongTensor(batch_size).random_(0, self.nb_items).tolist()\n",
    "        print('Generating validation negatives...')\n",
    "        for idx, u in enumerate(tqdm.tqdm(users.tolist())):\n",
    "            if not random_items:\n",
    "                random_items = torch.LongTensor(batch_size).random_(0, self.nb_items).tolist()\n",
    "            j = random_items.pop()\n",
    "            while u * self.nb_items + j in self.set:\n",
    "                if not random_items:\n",
    "                    random_items = torch.LongTensor(batch_size).random_(0, self.nb_items).tolist()\n",
    "                j = random_items.pop()\n",
    "\n",
    "            items[idx] = j\n",
    "        items = torch.LongTensor(items)\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000263 ratings on 26744 items from 138493 users from 1995-01-09 11:46:44 to 2015-03-31 06:40:02\n",
      "Filtering out users with less than 20 ratings\n",
      "Mapping original user and item IDs to new sequential IDs\n"
     ]
    }
   ],
   "source": [
    "df = implicit_load('/data/ml-20m/ratings.csv', sort=False)\n",
    "\n",
    "print(\"Filtering out users with less than {} ratings\".format(MIN_RATINGS))\n",
    "grouped = df.groupby(USER_COLUMN)\n",
    "df = grouped.filter(lambda x: len(x) >= MIN_RATINGS)\n",
    "\n",
    "print(\"Mapping original user and item IDs to new sequential IDs\")\n",
    "df[USER_COLUMN], unique_users = pd.factorize(df[USER_COLUMN])\n",
    "df[ITEM_COLUMN], unique_items = pd.factorize(df[ITEM_COLUMN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               0\n",
       "1               1\n",
       "2               2\n",
       "3               3\n",
       "4               4\n",
       "5               5\n",
       "6               6\n",
       "7               7\n",
       "8               8\n",
       "9               9\n",
       "10             10\n",
       "11             11\n",
       "12             12\n",
       "13             13\n",
       "14             14\n",
       "15             15\n",
       "16             16\n",
       "17             17\n",
       "18             18\n",
       "19             19\n",
       "20             20\n",
       "21             21\n",
       "22             22\n",
       "23             23\n",
       "24             24\n",
       "25             25\n",
       "26             26\n",
       "27             27\n",
       "28             28\n",
       "29             29\n",
       "            ...  \n",
       "20000233      960\n",
       "20000234     3832\n",
       "20000235      962\n",
       "20000236     6121\n",
       "20000237     3996\n",
       "20000238     1944\n",
       "20000239     2603\n",
       "20000240      971\n",
       "20000241     1945\n",
       "20000242      972\n",
       "20000243      974\n",
       "20000244     1953\n",
       "20000245     5180\n",
       "20000246      988\n",
       "20000247      989\n",
       "20000248     9547\n",
       "20000249     1001\n",
       "20000250     3938\n",
       "20000251     1805\n",
       "20000252     1007\n",
       "20000253     6156\n",
       "20000254     1810\n",
       "20000255     1812\n",
       "20000256    11011\n",
       "20000257     1036\n",
       "20000258     1814\n",
       "20000259     1037\n",
       "20000260     3950\n",
       "20000261     1818\n",
       "20000262     4010\n",
       "Name: item_id, Length: 20000263, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[ITEM_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     1,      2,      3,      4,      5,      6,      7,      8,\n",
       "                 9,     10,\n",
       "            ...\n",
       "            138484, 138485, 138486, 138487, 138488, 138489, 138490, 138491,\n",
       "            138492, 138493],\n",
       "           dtype='int64', length=138493)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([     2,     29,     32,     47,     50,    112,    151,    223,\n",
       "               253,    260,\n",
       "            ...\n",
       "            104307, 106170, 106401, 113539, 118856, 121017, 121019, 121021,\n",
       "            110167, 110510],\n",
       "           dtype='int64', length=26744)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./mappings.pickle', 'wb') as handle:\n",
    "    pickle.dump({\"users\": unique_users, \"items\": unique_items}, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to sort before popping to get last item\n",
    "df.sort_values(by='timestamp', inplace=True)\n",
    "\n",
    "# clean up data\n",
    "del df['rating'], df['timestamp']\n",
    "df = df.drop_duplicates() # assuming it keeps order\n",
    "\n",
    "# now we have filtered and sorted by time data, we can split test data out\n",
    "grouped_sorted = df.groupby(USER_COLUMN, group_keys=False)\n",
    "test_data = grouped_sorted.tail(1).sort_values(by='user_id')\n",
    "# need to pop for each group\n",
    "train_data = grouped_sorted.apply(lambda x: x.iloc[:-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: no way to keep reference training data ordering because use of python set and multi-process\n",
    "# It should not matter since it will be later randomized again\n",
    "# save train and val data that is fixed.\n",
    "train_ratings = torch.from_numpy(train_data.values)\n",
    "torch.save(train_ratings, './train_ratings.pt')\n",
    "test_ratings = torch.from_numpy(test_data.values)\n",
    "torch.save(test_ratings, './test_ratings.pt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19861770, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,     62],\n",
       "        [     1,     15],\n",
       "        [     2,    336],\n",
       "        ...,\n",
       "        [138490,    173],\n",
       "        [138491,    204],\n",
       "        [138492,    695]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 80696/13849300 [00:00<00:17, 806955.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating validation negatives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13849300/13849300 [00:14<00:00, 966810.44it/s]\n"
     ]
    }
   ],
   "source": [
    "sampler = _TestNegSampler(train_ratings.cpu().numpy(), 100)  # using 100 negative samples\n",
    "test_negs = sampler.generate().cuda()\n",
    "test_negs = test_negs.reshape(-1, 100)\n",
    "torch.save(test_negs, './test_negatives.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([138493, 100])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_negs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14470, 19596,  5496,  7876, 13781, 18589, 13426, 10928,  4491,  9756,\n",
       "         8371, 16324, 19714, 17614, 17084, 10339, 19900, 19954,  3198,  7704,\n",
       "        21833, 24603, 22393, 16497, 12137, 10897, 16824,  6476, 19759,  9787,\n",
       "         2589, 19789,  6598, 18668, 26078, 23213,  8732, 20727, 11042, 13098,\n",
       "        19331,  2694,   774, 16017,  2733,  7195,  3234,  5478,  9518, 25528,\n",
       "        12890, 20064,  4193, 24937, 21779, 20982,  4279, 13174,  2057,  8464,\n",
       "         4302, 18896,   546, 17086,  3973, 15116, 24690, 23495, 15982,  9509,\n",
       "        11061, 16351,  5154, 13412, 18309, 12249,  3764, 22858, 25954,  1904,\n",
       "         7456, 24602, 26063, 15207, 18617,  9906, 21567,  7472, 17297,  6302,\n",
       "         9482, 15818,  6989, 14464,  2344, 10292, 23338,  6301, 22121,  7240],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_negs[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
