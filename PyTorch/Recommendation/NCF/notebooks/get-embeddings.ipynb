{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python -m torch.distributed.launch --nproc_per_node=1 --use_env ./ncf.py --epochs 50 --data /data/cache/ml-20m --checkpoint_dir ./saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLL 2020-08-16 07:08:55.406353 - PARAMETER data : /data/cache/ml-20m  epochs : 50  batch_size : 1048576  valid_batch_size : 1048576  factors : 64  layers : [256, 256, 128, 64]  negative_samples : 4  learning_rate : 0.0045  topk : 10  seed : None  threshold : 1.0  beta1 : 0.25  beta2 : 0.5  eps : 1e-08  dropout : 0.5  checkpoint_dir : ./saved_model  load_checkpoint_path : None  mode : train  grads_accumulated : 1  amp : False  log_path : log.json  world_size : 1  distributed : False  local_rank : 0 \n",
      "Saving results to ./saved_model\n",
      "NeuMF(\n",
      "  (mf_user_embed): Embedding(138493, 64)\n",
      "  (mf_item_embed): Embedding(26744, 64)\n",
      "  (mlp_user_embed): Embedding(138493, 128)\n",
      "  (mlp_item_embed): Embedding(26744, 128)\n",
      "  (mlp): ModuleList(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  )\n",
      "  (final): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "31832577 parameters\n",
      "> /workspace/recommendation/ncf.py(163)val_epoch()\n",
      "-> print('=============AUC: %f'%(roc_auc_score(y, temp)))\n",
      "(Pdb) \n",
      "--KeyboardInterrupt--\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "(Pdb)     \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/launch.py\", line 263, in <module>\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.6/site-packages/torch/distributed/launch.py\", line 256, in main\n",
      "    process.wait()\n",
      "  File \"/opt/conda/lib/python3.6/subprocess.py\", line 1477, in wait\n",
      "    (pid, sts) = self._try_wait(0)\n",
      "  File \"/opt/conda/lib/python3.6/subprocess.py\", line 1424, in _try_wait\n",
      "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!rm -rf ./saved_model\n",
    "!python -m torch.distributed.launch --nproc_per_node=1 --use_env ../ncf.py --epochs 50 --data /data/cache/ml-20m --checkpoint_dir ./saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 124356\r\n",
      "-rw-r--r-- 1 root root 127332376 Aug 16 06:09 model.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/workspace/recommendation\")\n",
    "\n",
    "import torch.jit\n",
    "import time\n",
    "from argparse import ArgumentParser\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from neumf import NeuMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = ArgumentParser(description=\"Benchmark inference performance of the NCF model\")\n",
    "    parser.add_argument('-f', '--file', help='Path for input file. First line should contain number of lines to search in')\n",
    "    parser.add_argument('--load_checkpoint_path', default=None, type=str,\n",
    "                        help='Path to the checkpoint file to be loaded before training/evaluation')\n",
    "    parser.add_argument('--n_users', default=138493, type=int,\n",
    "                        help='Number of users. Defaults to the number of users in the ml-20m dataset after preprocessing')\n",
    "    parser.add_argument('--n_items', default=26744, type=int,\n",
    "                        help='Number of items. Defaults to the number of users in the ml-20m dataset after preprocessing')\n",
    "    parser.add_argument('-fac', '--factors', type=int, default=64,\n",
    "                        help='Number of predictive factors')\n",
    "    parser.add_argument('--dropout', type=float, default=0.5,\n",
    "                        help='Dropout probability, if equal to 0 will not use dropout at all')\n",
    "    parser.add_argument('--layers', nargs='+', type=int,\n",
    "                        default=[256, 256, 128, 64],\n",
    "                        help='Sizes of hidden layers for MLP')\n",
    "    parser.add_argument('--batch_sizes', default='1,4,16,64,256,1024,4096,16384,65536,262144,1048576', type=str,\n",
    "                        help='A list of comma-separated batch size values to benchmark')\n",
    "    parser.add_argument('--num_batches', default=200, type=int,\n",
    "                        help='Number of batches for which to measure latency and throughput')\n",
    "    parser.add_argument('--fp16', action='store_true', help='Cast the model to FP16 precision', default=False)\n",
    "    parser.add_argument('--log_path', default='log.json', type=str,\n",
    "                        help='Path for the JSON training log')\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_movies(nn_movie_id, item_embedding, item_embedding_norm=None, k=10):\n",
    "    #if not item_embedding_norm:\n",
    "    #    item_embedding_norm = np.linalg.norm(item_embedding, axis=1)\n",
    "    #sim = np.dot(item_embedding, item_embedding[nn_movie_id].reshape(64, 1)).squeeze()/item_embedding_norm\n",
    "    \n",
    "    sim = 1-cdist(item_embedding, item_embedding[nn_movie_id].reshape(1, -1), metric=\"cosine\")\n",
    "\n",
    "    #sim = -cdist(item_embedding, item_embedding[nn_movie_id].reshape(1, -1), metric=\"euclidean\")\n",
    "    \n",
    "    return sim.squeeze().argsort()[-k:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../saved_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuMF(nb_users=args.n_users, nb_items=args.n_items, mf_dim=args.factors,\n",
    "              mlp_layer_sizes=args.layers, dropout=args.dropout)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "state_dict = torch.load(\"../saved_model/model.pth\")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "#find nearest neighbor\n",
    "item_embedding = model.mf_item_embed.weight\n",
    "item_embedding = item_embedding.detach().cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-item similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  Jumanji (1995) Adventure|Children|Fantasy\n",
      "Similar movies: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cdist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b9a9bdf98f27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Similar movies: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0msimilar_movies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_similar_movies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovies_to_nn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmovie_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msimilar_movies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-e26874243f69>\u001b[0m in \u001b[0;36mfind_similar_movies\u001b[0;34m(nn_movie_id, item_embedding, item_embedding_norm, k)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#sim = np.dot(item_embedding, item_embedding[nn_movie_id].reshape(64, 1)).squeeze()/item_embedding_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn_movie_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cosine\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#sim = -cdist(item_embedding, item_embedding[nn_movie_id].reshape(1, -1), metric=\"euclidean\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cdist' is not defined"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./mappings.pickle', 'rb') as handle:\n",
    "    movies_mapping = pickle.load(handle)[\"items\"]\n",
    "\n",
    "nn_to_movies = movies_mapping\n",
    "movies_to_nn = {}\n",
    "for i in range(len(movies_mapping)):\n",
    "    movies_to_nn[movies_mapping[i]] = i\n",
    "\n",
    "import pandas as pd\n",
    "movies = pd.read_csv(\"/data/ml-20m/movies.csv\", index_col=\"movieId\")\n",
    "\n",
    "movie_ID = 2\n",
    "print(\"Query: \", movies.ix[movie_ID][\"title\"], movies.ix[movie_ID][\"genres\"])\n",
    "\n",
    "print(\"Similar movies: \")\n",
    "similar_movies = find_similar_movies(movies_to_nn[movie_ID], item_embedding)\n",
    "\n",
    "for i in similar_movies:\n",
    "    print(movies.ix[nn_to_movies[i]][\"title\"], movies.ix[nn_to_movies[i]][\"genres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ID = 1\n",
    "print(\"Query: \", movies.ix[movie_ID][\"title\"], movies.ix[movie_ID][\"genres\"])\n",
    "\n",
    "print(\"Similar movies: \")\n",
    "similar_movies = find_similar_movies(movies_to_nn[movie_ID], item_embedding)\n",
    "\n",
    "for i in similar_movies:\n",
    "    print(movies.ix[nn_to_movies[i]][\"title\"], movies.ix[nn_to_movies[i]][\"genres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embedding = model.mf_user_embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_embedding = model.mf_item_embed.weight\n",
    "\n",
    "item_embedding = model.mlp_item_embed.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.dot(item_embedding[0], item_embedding[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy\n",
    "item_embedding = item_embedding.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embedding_norm = np.linalg.norm(item_embedding, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_embedding_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = np.dot(item_embedding, item_embedding[0].reshape(-1, 1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sim/item_embedding_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sim.squeeze().argsort()[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "cosine_sim = 1-cdist(item_embedding, item_embedding[0].reshape(1, -1), metric=\"cosine\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim.squeeze().argsort()[-10:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_sim = -cdist(item_embedding, item_embedding[0].reshape(1, -1), metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /data/ml-20m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies = pd.read_csv(\"/data/ml-20m/movies.csv\", index_col=\"movieId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./mappings.pickle', 'rb') as handle:\n",
    "    movies_mapping = pickle.load(handle)[\"items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_to_movies = movies_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_to_nn = {}\n",
    "for i in range(len(movies_mapping)):\n",
    "    movies_to_nn[movies_mapping[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_to_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max(movies_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(movies_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.ix[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_movies(nn_movie_id, item_embedding, item_embedding_norm=None, k=10):\n",
    "    #if not item_embedding_norm:\n",
    "    #    item_embedding_norm = np.linalg.norm(item_embedding, axis=1)\n",
    "    #sim = np.dot(item_embedding, item_embedding[nn_movie_id].reshape(64, 1)).squeeze()/item_embedding_norm\n",
    "    \n",
    "    sim = 1-cdist(item_embedding, item_embedding[nn_movie_id].reshape(1, -1), metric=\"cosine\")\n",
    "\n",
    "    #sim = -cdist(item_embedding, item_embedding[nn_movie_id].reshape(1, -1), metric=\"euclidean\")\n",
    "    \n",
    "    return sim.squeeze().argsort()[-k:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar_movies(1, item_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "movie_ID = 1\n",
    "print(\"Query: \", movies.ix[movie_ID][\"title\"], movies.ix[movie_ID][\"genres\"])\n",
    "\n",
    "print(\"Similar movies: \")\n",
    "similar_movies = find_similar_movies(movies_to_nn[movie_ID], item_embedding)\n",
    "\n",
    "for i in similar_movies:\n",
    "    print(movies.ix[nn_to_movies[i]][\"title\"], movies.ix[nn_to_movies[i]][\"genres\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
